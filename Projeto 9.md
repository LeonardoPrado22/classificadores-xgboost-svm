# Projeto 9 ‚Äî Otimiza√ß√£o de Classificadores com XGBoost e SVM

---

## üìö Explica√ß√£o do Curso
Este projeto foi desenvolvido como parte do curso de Cientista de Dados da EBAC, focando no dom√≠nio de dois dos algoritmos de classifica√ß√£o mais poderosos e essenciais para o mercado: o modelo de *Ensemble* **XGBoost (Extreme Gradient Boosting)** e a m√°quina de separa√ß√£o de dados **Support Vector Machine (SVM)**. O objetivo √© aplicar e comparar esses modelos em uma base de dados de propens√£o √† compra de carros.

---

## üéØ Objetivos
O principal objetivo deste projeto √© a consolida√ß√£o de t√©cnicas avan√ßadas de classifica√ß√£o:

* **Implementa√ß√£o do XGBoost:** Aplicar o algoritmo XGBoost para obter alta performance na classifica√ß√£o de clientes.
* **Implementa√ß√£o do SVM:** Utilizar o Support Vector Machine (SVM), explorando a aplica√ß√£o de diferentes *kernels* (como Linear e Polinomial) para encontrar o melhor hiperplano de separa√ß√£o de classes.
* **Compara√ß√£o de Modelos:** Comparar o desempenho e os resultados de XGBoost e SVM para determinar qual modelo √© mais robusto e eficaz para o *dataset* de propens√£o √† compra.
* **Consolida√ß√£o de Modelos Avan√ßados:** Consolidar o entendimento sobre a aplica√ß√£o de modelos de *Ensemble* e modelos baseados em *Kernel*.

---

## üíª Tecnologias Usadas
* **Linguagem:** Python
* **Algoritmos Principais:** XGBoost e Support Vector Classifier (SVC/SVM).
* **Bibliotecas Principais:** Pandas, Scikit-learn (SVC), XGBoost.
* **Pr√©-processamento:** `LabelEncoder` (para vari√°veis categ√≥ricas como "Gender").
* **Ambiente:** Jupyter Notebook.

---

## üìà Principais An√°lises Realizadas
O projeto focou nas seguintes etapas de prepara√ß√£o, modelagem e compara√ß√£o:

* **Pr√©-processamento de Dados:** Tratamento da base de dados (Propens√£o √† Compra de Carros), incluindo o *drop* da coluna 'User ID' e aplica√ß√£o do `Label Encoder` na coluna 'Gender'.
* **Modelagem XGBoost:** Treinamento do modelo **XGBoost** para classificar clientes com alta e baixa probabilidade de convers√£o, buscando uma das maiores acur√°cias poss√≠veis.
* **Modelagem SVM:** Implementa√ß√£o do **SVM** com o *kernel* Polinomial e o *kernel* Linear, comparando qual gerou as melhores m√©tricas (Acur√°cia, Recall).
* **An√°lise de M√©tricas:** Avalia√ß√£o dos modelos atrav√©s das m√©tricas de classifica√ß√£o, com foco na an√°lise comparativa do **Recall** e **Precision** para a classe minorit√°ria.

---

## ‚ú® Insights Chave (Conclus√£o)

O exerc√≠cio demonstrou o dom√≠nio das t√©cnicas avan√ßadas de classifica√ß√£o, provando a capacidade de ir al√©m dos modelos de *baseline*:

* **Superioridade do XGBoost:** A an√°lise comparativa confirmou a **superioridade do XGBoost** em rela√ß√£o ao SVM na maioria das m√©tricas para este problema, estabelecendo-o como o modelo mais eficaz para a previs√£o de propens√£o √† compra de carros.
* **Valida√ß√£o de Baseline:** O exerc√≠cio tamb√©m validou a Regress√£o Log√≠stica como um excelente modelo de *baseline*, refor√ßando que os modelos mais complexos (XGBoost) devem justificar seu uso com um ganho significativo de performance.
* **Dom√≠nio T√©cnico:** O projeto refor√ßou a habilidade de implementar e comparar modelos de ponta, essenciais para a √°rea de Ci√™ncia de Dados.